{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate training data for Mask RCNN for brats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brats/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import nibabel as nib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGG_RAW_PATH      = '/media/brats/MyPassport/Avinash/Kaminstas_2018/MICCAI_BraTS_2018_Data_Training/HGG'\n",
    "LGG_RAW_PATH      = '/media/brats/MyPassport/Avinash/Kaminstas_2018/MICCAI_BraTS_2018_Data_Training/LGG'\n",
    "\n",
    "H5_PATH_TRAIN     = '/media/brats/MyPassport/Avinash/Kaminstas_2018/MICCAI_BraTS_2018_Data_Training/v_hdf5_data/train_set'\n",
    "H5_PATH_VALID     = '/media/brats/MyPassport/Avinash/Kaminstas_2018/MICCAI_BraTS_2018_Data_Training/v_hdf5_data/valid_set'\n",
    "\n",
    "csv_path = '/media/brats/MyPassport/Avinash/Kaminstas_2018/Modified_Kamnistas_Model_2018/DataGenerator/train_valid_test_split.csv'\n",
    "info     = pd.read_csv(csv_path)\n",
    "\n",
    "train_info = info[info['Training']].as_matrix()[:,1]\n",
    "valid_info = info[info['Validation']].as_matrix()[:,1]\n",
    "\n",
    "train_HGG  = np.array([path.split('/').pop() for path in train_info if path.__contains__('HGG')])\n",
    "valid_HGG  = np.array([path.split('/').pop() for path in valid_info if path.__contains__('HGG')])\n",
    "\n",
    "train_LGG  = np.array([path.split('/').pop() for path in train_info if path.__contains__('LGG')])\n",
    "valid_LGG  = np.array([path.split('/').pop() for path in valid_info if path.__contains__('LGG')])\n",
    "\n",
    "HGG_IDS    = np.concatenate([train_HGG, valid_HGG])\n",
    "LGG_IDS    = np.concatenate([train_LGG, valid_LGG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_HGG_patients_to_train= len(train_HGG)\n",
    "no_of_LGG_patients_to_train= len(train_LGG)\n",
    "no_of_HGG_patients_to_valid= len(valid_HGG)\n",
    "no_of_LGG_patients_to_valid= len(valid_LGG)\n",
    "\n",
    "hgg_id_list = HGG_IDS\n",
    "lgg_id_list = LGG_IDS\n",
    "\n",
    "hgg_total_number= len(HGG_IDS)\n",
    "lgg_total_number= len(LGG_IDS)\n",
    "lgg_total_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_every_slice_between_0_to_255(a):\n",
    "    normalized_a=  255*((a-np.min(a))/(np.max(a)-np.min(a)))\n",
    "    return normalized_a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e7bba55bef4761b073c5a329655c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=143), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brats/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(no_of_HGG_patients_to_train)):\n",
    "#     print ('patient id',hgg_id_list[i])\n",
    "    sequences= os.listdir(HGG_RAW_PATH+\"/\"+hgg_id_list[i])\n",
    "    counter =0\n",
    "    for s in sequences:\n",
    "        if \"flair\" in s:\n",
    "            flair = HGG_RAW_PATH+\"/\"+hgg_id_list[i]+\"/\"+s\n",
    "        if \"t2\" in s:\n",
    "            t2 = HGG_RAW_PATH+\"/\"+hgg_id_list[i]+\"/\"+s\n",
    "        if \"t1ce\" in s:\n",
    "            t1c = HGG_RAW_PATH+\"/\"+hgg_id_list[i]+\"/\"+s\n",
    "        if \"t1\" in s and 't1ce' not in s:\n",
    "            t1 = HGG_RAW_PATH+\"/\"+hgg_id_list[i]+\"/\"+s\n",
    "        if \"seg\" in s:\n",
    "            seg = HGG_RAW_PATH+'/'+hgg_id_list[i]+\"/\"+s\n",
    "        if \"mask\" in s:\n",
    "            mask =HGG_RAW_PATH+'/'+hgg_id_list[i]+\"/\"+s\n",
    "            \n",
    "\n",
    "    flair_v= nib.load(flair).get_data()\n",
    "    t2_v=    nib.load(t2).get_data()\n",
    "    t1c_v=   nib.load(t1c).get_data()\n",
    "    t1_v=   nib.load(t1).get_data() \n",
    "    \n",
    "    seg_v=   nib.load(seg).get_data()\n",
    "    mask_v=  nib.load(mask).get_data()\n",
    "\n",
    "    \n",
    "\n",
    "    x,y,z = np.where (seg_v !=0)\n",
    "    \n",
    "    for slices in np.unique(z):\n",
    "        \n",
    "        fl   = scale_every_slice_between_0_to_255(np.transpose(flair_v[:,:,slices]))\n",
    "        t2   = scale_every_slice_between_0_to_255(np.transpose(t2_v   [:,:,slices]))\n",
    "        t1ce = scale_every_slice_between_0_to_255(np.transpose(t1c_v  [:,:,slices]))\n",
    "        t1 = scale_every_slice_between_0_to_255(np.transpose(t1_v  [:,:,slices]))\n",
    "        \n",
    "        sege = np.transpose(seg_v  [:,:,slices])\n",
    "        maske= np.transpose(mask_v[:,:,slices])\n",
    "        \n",
    "        x,y  = np.where (sege!=0)\n",
    "        if len(x) > 50:\n",
    "            array=  np.zeros((fl.shape[0],fl.shape[1],3),dtype=fl.dtype)\n",
    "            array[:,:,0]= fl\n",
    "            array[:,:,1]= t2\n",
    "            array[:,:,2]= t1ce\n",
    "#             array[:,:,3]= t1\n",
    "\n",
    "\n",
    "            counter = counter +1\n",
    "\n",
    "            name_scheme= hgg_id_list[i] + '_'+ str(counter)\n",
    "            dest_path = os.path.join(H5_PATH_TRAIN,name_scheme +'.hdf5')\n",
    "#             print (dest_path)\n",
    "            hp = h5py.File(dest_path,'w')\n",
    "            hp.create_dataset('Sequence', data=array)       \n",
    "            hp.create_dataset('label', data=sege)\n",
    "            hp.create_dataset('mask',data=maske)\n",
    "            hp.close()\n",
    "        \n",
    "    ## Added to take few slices without any lesion\n",
    "    x,y,z = np.where (seg_v ==0)\n",
    "    slices_without_lesion= np.unique(z)\n",
    "    ## np.random.shuffle the above array\n",
    "    slices_without_lesion = shuffle(slices_without_lesion, random_state=0)\n",
    "    ## take half the number of slices without lesion\n",
    "    num_of_no_instance_slices= len(slices_without_lesion)//3\n",
    "    \n",
    "    for sl in range(num_of_no_instance_slices):\n",
    "        slices = slices_without_lesion[sl]\n",
    "        fl   = scale_every_slice_between_0_to_255(np.transpose(flair_v[:,:,slices]))\n",
    "        t2   = scale_every_slice_between_0_to_255(np.transpose(t2_v   [:,:,slices]))\n",
    "        t1ce = scale_every_slice_between_0_to_255(np.transpose(t1c_v  [:,:,slices]))\n",
    "        t1 = scale_every_slice_between_0_to_255(np.transpose(t1_v  [:,:,slices])) \n",
    "        \n",
    "        sege = np.transpose(seg_v  [:,:,slices])\n",
    "        maske= np.transpose(mask_v [:,:,slices])\n",
    "        \n",
    "        array=  np.zeros((fl.shape[0],fl.shape[1],3),dtype=fl.dtype)\n",
    "        array[:,:,0]= fl\n",
    "        array[:,:,1]= t2\n",
    "        array[:,:,2]= t1ce\n",
    "#         array[:,:,3]= t1        \n",
    "        counter = counter +1\n",
    "        \n",
    "        name_scheme= hgg_id_list[i] + '_'+ str(counter)\n",
    "        dest_path = os.path.join(H5_PATH_TRAIN,name_scheme +'.hdf5')\n",
    "#         print (dest_path)\n",
    "        hp = h5py.File(dest_path,'w')\n",
    "        hp.create_dataset('Sequence', data=array)       \n",
    "        hp.create_dataset('label', data=sege)\n",
    "        hp.create_dataset('mask',data=maske)\n",
    "        hp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dd76f1a1d042b9b502f6ec34eb627e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brats/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(no_of_HGG_patients_to_train,no_of_HGG_patients_to_train+no_of_HGG_patients_to_valid)):\n",
    "#     print ('patient id',hgg_id_list[i])\n",
    "    sequences= os.listdir(HGG_RAW_PATH+\"/\"+hgg_id_list[i])\n",
    "    counter =0\n",
    "    for s in sequences:\n",
    "        if \"flair\" in s:\n",
    "            flair = HGG_RAW_PATH+\"/\"+hgg_id_list[i]+\"/\"+s\n",
    "        if \"t2\" in s:\n",
    "            t2 = HGG_RAW_PATH+\"/\"+hgg_id_list[i]+\"/\"+s\n",
    "        if \"t1ce\" in s:\n",
    "            t1c = HGG_RAW_PATH+\"/\"+hgg_id_list[i]+\"/\"+s\n",
    "        if \"t1\" in s and 't1ce' not in s:\n",
    "            t1 = HGG_RAW_PATH+\"/\"+hgg_id_list[i]+\"/\"+s\n",
    "        if \"seg\" in s:\n",
    "            seg = HGG_RAW_PATH+'/'+hgg_id_list[i]+\"/\"+s\n",
    "        if \"mask\" in s:\n",
    "            mask =HGG_RAW_PATH+'/'+hgg_id_list[i]+\"/\"+s\n",
    "            \n",
    "    flair_v= nib.load(flair).get_data()\n",
    "    t2_v =    nib.load(t2).get_data()\n",
    "    t1c_v=   nib.load(t1c).get_data()\n",
    "    t1_v =  nib.load(t1).get_data()\n",
    "    \n",
    "    seg_v=   nib.load(seg).get_data()\n",
    "    mask_v=nib.load(mask).get_data()\n",
    "    \n",
    " \n",
    "    x,y,z = np.where (seg_v !=0)\n",
    "    \n",
    "    for slices in np.unique(z):\n",
    "        \n",
    "        fl   = scale_every_slice_between_0_to_255(np.transpose(flair_v[:,:,slices]))\n",
    "        t2   = scale_every_slice_between_0_to_255(np.transpose(t2_v   [:,:,slices]))\n",
    "        t1ce = scale_every_slice_between_0_to_255(np.transpose(t1c_v  [:,:,slices]))\n",
    "        t1 = scale_every_slice_between_0_to_255(np.transpose(t1_v  [:,:,slices]))\n",
    "        \n",
    "        sege = np.transpose(seg_v  [:,:,slices])\n",
    "        maske= np.transpose(mask_v[:,:,slices])\n",
    "        \n",
    "        x,y  = np.where (sege!=0)\n",
    "        if len(x) > 50:\n",
    "            array=  np.float32(np.zeros((fl.shape[0],fl.shape[1],4)))\n",
    "            array[:,:,0]= fl\n",
    "            array[:,:,1]= t2\n",
    "            array[:,:,2]= t1ce\n",
    "            array[:,:,3]= t1\n",
    "            \n",
    "            counter = counter +1\n",
    "\n",
    "            name_scheme= hgg_id_list[i] + '_'+ str(counter)\n",
    "            dest_path = os.path.join(H5_PATH_VALID, name_scheme +'.hdf5')\n",
    "            hp = h5py.File(dest_path,'w')\n",
    "            hp.create_dataset('Sequence', data=array)       \n",
    "            hp.create_dataset('label', data=sege)\n",
    "            hp.create_dataset('mask', data=maske)   \n",
    "            hp.close()\n",
    "\n",
    "    ## Added to take few slices without any lesion\n",
    "    x,y,z = np.where (seg_v ==0)\n",
    "    slices_without_lesion= np.unique(z)\n",
    "    ## shuffle the above array\n",
    "    slices_without_lesion = shuffle(slices_without_lesion, random_state=0)\n",
    "    ## take half the number of slices without lesion\n",
    "    num_of_no_instance_slices= len(slices_without_lesion)//3\n",
    "    \n",
    "    for sl in range(num_of_no_instance_slices):\n",
    "        slices = slices_without_lesion[sl]\n",
    "        fl   = scale_every_slice_between_0_to_255(np.transpose(flair_v[:,:,slices]))\n",
    "        t2   = scale_every_slice_between_0_to_255(np.transpose(t2_v   [:,:,slices]))\n",
    "        t1ce = scale_every_slice_between_0_to_255(np.transpose(t1c_v  [:,:,slices]))\n",
    "        t1 = scale_every_slice_between_0_to_255(np.transpose(t1_v  [:,:,slices]))   \n",
    "        \n",
    "        sege = np.transpose(seg_v  [:,:,slices])\n",
    "        maske= np.transpose(mask_v  [:,:,slices])\n",
    "        array=  np.float32(np.zeros((fl.shape[0],fl.shape[1],4)))\n",
    "        array[:,:,0]= fl\n",
    "        array[:,:,1]= t2\n",
    "        array[:,:,2]= t1ce\n",
    "        array[:,:,3]= t1        \n",
    "        \n",
    "        counter = counter +1\n",
    "        \n",
    "        name_scheme= hgg_id_list[i] + '_'+ str(counter)\n",
    "        dest_path = os.path.join(H5_PATH_VALID,name_scheme +'.hdf5')\n",
    "        hp = h5py.File(dest_path,'w')\n",
    "        hp.create_dataset('Sequence', data=array)       \n",
    "        hp.create_dataset('label', data=sege)\n",
    "        hp.create_dataset('mask', data=maske)\n",
    "        hp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8197359f994655b317ea9fba22800a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=52), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brats/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(no_of_LGG_patients_to_train)):\n",
    "#     print ('patient id',lgg_id_list[i])\n",
    "    sequences= os.listdir(LGG_RAW_PATH+\"/\"+lgg_id_list[i])\n",
    "    counter =0\n",
    "    for s in sequences:\n",
    "        if \"flair\" in s:\n",
    "            flair = LGG_RAW_PATH+\"/\"+lgg_id_list[i]+\"/\"+s\n",
    "        if \"t2\" in s:\n",
    "            t2 = LGG_RAW_PATH+\"/\"+lgg_id_list[i]+\"/\"+s\n",
    "        if \"t1ce\" in s:\n",
    "            t1c = LGG_RAW_PATH+\"/\"+lgg_id_list[i]+\"/\"+s\n",
    "        if \"t1\" in s and \"t1ce\" not in s:\n",
    "            t1 = LGG_RAW_PATH+\"/\"+lgg_id_list[i]+\"/\"+s            \n",
    "        if \"seg\" in s:\n",
    "            seg = LGG_RAW_PATH+'/'+lgg_id_list[i]+\"/\"+s\n",
    "        if \"mask\" in s:\n",
    "            mask= LGG_RAW_PATH+'/'+lgg_id_list[i]+\"/\"+s\n",
    "        \n",
    "    flair_v= nib.load(flair).get_data()\n",
    "    t2_v=    nib.load(t2).get_data()\n",
    "    t1c_v=   nib.load(t1c).get_data()\n",
    "    t1_v=   nib.load(t1).get_data()\n",
    "    \n",
    "    seg_v=   nib.load(seg).get_data()\n",
    "    mask_v=   nib.load(mask).get_data()    \n",
    "    \n",
    "    x,y,z = np.where (seg_v !=0)\n",
    "    \n",
    "    for slices in np.unique(z):\n",
    "        \n",
    "        fl   = scale_every_slice_between_0_to_255(np.transpose(flair_v[:,:,slices]))\n",
    "        t2   = scale_every_slice_between_0_to_255(np.transpose(t2_v   [:,:,slices]))\n",
    "        t1ce = scale_every_slice_between_0_to_255(np.transpose(t1c_v  [:,:,slices]))\n",
    "        t1 = scale_every_slice_between_0_to_255(np.transpose(t1_v  [:,:,slices]))\n",
    "        \n",
    "        sege = np.transpose(seg_v  [:,:,slices])\n",
    "        maske = np.transpose(mask_v  [:,:,slices])       \n",
    "        x,y  = np.where (sege!=0)\n",
    "        if len(x) > 50:\n",
    "            array=  np.zeros((fl.shape[0],fl.shape[1],4),dtype=fl.dtype)\n",
    "            array[:,:,0]= fl\n",
    "            array[:,:,1]= t2\n",
    "            array[:,:,2]= t1ce\n",
    "            array[:,:,3]= t1\n",
    "            \n",
    "            counter = counter +1\n",
    "\n",
    "            name_scheme= lgg_id_list[i] + '_'+ str(counter)\n",
    "            dest_path =os.path.join(H5_PATH_TRAIN,name_scheme +'.hdf5')\n",
    "            hp = h5py.File(dest_path,'w')\n",
    "            hp.create_dataset('Sequence', data=array)       \n",
    "            hp.create_dataset('label', data=sege)\n",
    "            hp.create_dataset('mask', data=maske)            \n",
    "            hp.close()\n",
    "\n",
    "    ## Added to take few slices without any lesion\n",
    "    x,y,z = np.where (seg_v ==0)\n",
    "    slices_without_lesion= np.unique(z)\n",
    "    ## shuffle the above array\n",
    "    slices_without_lesion = shuffle(slices_without_lesion, random_state=0)\n",
    "    ## take half the number of slices without lesion\n",
    "    num_of_no_instance_slices= len(slices_without_lesion)//3\n",
    "    \n",
    "    for sl in range(num_of_no_instance_slices):\n",
    "        slices = slices_without_lesion[sl]\n",
    "        fl   = scale_every_slice_between_0_to_255(np.transpose(flair_v[:,:,slices]))\n",
    "        t2   = scale_every_slice_between_0_to_255(np.transpose(t2_v   [:,:,slices]))\n",
    "        t1ce = scale_every_slice_between_0_to_255(np.transpose(t1c_v  [:,:,slices]))\n",
    "        t1 = scale_every_slice_between_0_to_255(np.transpose(t1_v  [:,:,slices]))\n",
    "        \n",
    "        sege = np.transpose(seg_v  [:,:,slices])\n",
    "        maske = np.transpose(mask_v  [:,:,slices])\n",
    "        \n",
    "        array=  np.zeros((fl.shape[0],fl.shape[1],4),dtype=fl.dtype)\n",
    "        array[:,:,0]= fl\n",
    "        array[:,:,1]= t2\n",
    "        array[:,:,2]= t1ce\n",
    "        array[:,:,3]= t1\n",
    "        \n",
    "        counter = counter +1\n",
    "        \n",
    "        name_scheme= lgg_id_list[i] + '_'+ str(counter)\n",
    "        dest_path = os.path.join(H5_PATH_TRAIN,name_scheme +'.hdf5')\n",
    "        hp = h5py.File(dest_path,'w')\n",
    "        hp.create_dataset('Sequence', data=array)       \n",
    "        hp.create_dataset('label', data=sege)\n",
    "        hp.create_dataset('mask', data=maske)\n",
    "        hp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5603a0cdbea14bd89aee10826e26fb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brats/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(no_of_LGG_patients_to_train,no_of_LGG_patients_to_train+no_of_LGG_patients_to_valid)):\n",
    "#     print ('patiend id', lgg_id_list[i])\n",
    "    sequences= os.listdir(LGG_RAW_PATH+\"/\"+lgg_id_list[i])\n",
    "    counter =0\n",
    "    for s in sequences:\n",
    "        if \"flair\" in s:\n",
    "            flair = LGG_RAW_PATH+\"/\"+lgg_id_list[i]+\"/\"+s\n",
    "        if \"t2\" in s:\n",
    "            t2 = LGG_RAW_PATH+\"/\"+lgg_id_list[i]+\"/\"+s\n",
    "        if \"t1ce\" in s:\n",
    "            t1c = LGG_RAW_PATH+\"/\"+lgg_id_list[i]+\"/\"+s\n",
    "        if \"t1\" in s and \"t1ce\" not in s:\n",
    "            t1 = LGG_RAW_PATH+\"/\"+lgg_id_list[i]+\"/\"+s \n",
    "        if \"seg\" in s:\n",
    "            seg = LGG_RAW_PATH+'/'+lgg_id_list[i]+\"/\"+s\n",
    "        if \"mask\" in s:\n",
    "            mask = LGG_RAW_PATH+'/'+lgg_id_list[i]+\"/\"+s\n",
    "        \n",
    "    flair_v= nib.load(flair).get_data()\n",
    "    t2_v=    nib.load(t2).get_data()\n",
    "    t1c_v=   nib.load(t1c).get_data()\n",
    "    t1_v=   nib.load(t1).get_data() \n",
    "    \n",
    "    seg_v=   nib.load(seg).get_data()\n",
    "    mask_v=   nib.load(mask).get_data()    \n",
    " \n",
    "    x,y,z = np.where (seg_v !=0)\n",
    "    \n",
    "    for slices in np.unique(z):\n",
    "        \n",
    "        fl   = scale_every_slice_between_0_to_255(np.transpose(flair_v[:,:,slices]))\n",
    "        t2   = scale_every_slice_between_0_to_255(np.transpose(t2_v   [:,:,slices]))\n",
    "        t1ce = scale_every_slice_between_0_to_255(np.transpose(t1c_v  [:,:,slices]))\n",
    "        t1   = scale_every_slice_between_0_to_255(np.transpose(t1_v  [:,:,slices]))  \n",
    "        \n",
    "        sege = np.transpose(seg_v  [:,:,slices])\n",
    "        maske = np.transpose(mask_v  [:,:,slices])\n",
    "        \n",
    "        x,y  = np.where (sege!=0)\n",
    "        if len(x) > 50:\n",
    "            array=  np.zeros((fl.shape[0],fl.shape[1],4),dtype=fl.dtype)\n",
    "            array[:,:,0]= fl\n",
    "            array[:,:,1]= t2\n",
    "            array[:,:,2]= t1ce\n",
    "            array[:,:,3]= t1\n",
    "            \n",
    "            counter = counter +1\n",
    "\n",
    "            name_scheme= lgg_id_list[i] + '_'+ str(counter)\n",
    "            dest_path = os.path.join(H5_PATH_VALID,name_scheme +'.hdf5')\n",
    "            hp = h5py.File(dest_path,'w')\n",
    "            hp.create_dataset('Sequence', data=array)       \n",
    "            hp.create_dataset('label', data=sege)\n",
    "            hp.create_dataset('mask', data=maske)\n",
    "            hp.close()\n",
    "        \n",
    "    ## Added to take few slices without any lesion\n",
    "    x,y,z = np.where (seg_v ==0)\n",
    "    slices_without_lesion= np.unique(z)\n",
    "    ## shuffle the above array\n",
    "    slices_without_lesion = shuffle(slices_without_lesion, random_state=0)\n",
    "    ## take half the number of slices without lesion\n",
    "    num_of_no_instance_slices= len(slices_without_lesion)//3\n",
    "    \n",
    "    for sl in range(num_of_no_instance_slices):\n",
    "        slices = slices_without_lesion[sl]\n",
    "        fl   = scale_every_slice_between_0_to_255(np.transpose(flair_v[:,:,slices]))\n",
    "        t2   = scale_every_slice_between_0_to_255(np.transpose(t2_v   [:,:,slices]))\n",
    "        t1ce = scale_every_slice_between_0_to_255(np.transpose(t1c_v  [:,:,slices]))\n",
    "        t1 = scale_every_slice_between_0_to_255(np.transpose(t1_v  [:,:,slices])) \n",
    "        \n",
    "        sege = np.transpose(seg_v  [:,:,slices])\n",
    "        maske = np.transpose(mask_v  [:,:,slices]) \n",
    "        \n",
    "        array=  np.zeros((fl.shape[0],fl.shape[1],4),dtype=fl.dtype)\n",
    "        array[:,:,0]= fl\n",
    "        array[:,:,1]= t2\n",
    "        array[:,:,2]= t1ce\n",
    "        array[:,:,3]= t1 \n",
    "        \n",
    "        counter = counter +1\n",
    "        \n",
    "        name_scheme= lgg_id_list[i] + '_'+ str(counter)\n",
    "        dest_path = os.path.join(H5_PATH_VALID,name_scheme +'.hdf5')\n",
    "        hp = h5py.File(dest_path,'w')\n",
    "        hp.create_dataset('Sequence', data=array)       \n",
    "        hp.create_dataset('label', data=sege)\n",
    "        hp.create_dataset('mask', data=maske)        \n",
    "        hp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patiend_id=[]\n",
    "for i in tqdm(range(no_of_LGG_patients_to_train+no_of_LGG_patients_to_valid,lgg_total_number)):\n",
    "    patiend_id.append(lgg_id_list[i])\n",
    "for i in tqdm(range(no_of_HGG_patients_to_train+no_of_HGG_patients_to_valid,hgg_total_number)):\n",
    "    patiend_id.append(hgg_id_list[i]) \n",
    "\n",
    "df= pd.DataFrame()\n",
    "df['patient_id']= patiend_id\n",
    "df.to_csv('Testing_patient_slices_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
